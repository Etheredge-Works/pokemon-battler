epochs: 1000
lightning_kwargs:
    replay_size: 1_000_000
    warm_start_steps: 2_000
    gamma: 0.99
    eps_start: 1.0
    eps_end: 0.01
    eps_last_frame: 1000_000  
    sync_rate: 10000
    lr: 0.0003 
    # how many samples per epoch
    episode_length: 1_600  # episode_length / batch_size = iters/ (steps per epoch)
    batch_size: 32
    stack_size: 32
    n_battles: 400
    eval_interval: 100
    obs_space: 1289
    #opponent_type: self
checkpoint_path: 'data/06_models/ckpt'
loss_type: mse
# TODO inject loss function

train_opponent: self
obs_space: 110
n_battles: 400
blessing_n_battles: 200

random_opponent: random
max_opponent: max_damage
self_opponent: self

battle_format: gen8randombattle
observation_space: 108

dqn_kwargs:
    obs_size: 66
    n_actions: 17
    hidden_size: 128
    stack_size: 1
    num_layers: 2
    out_channels: 4
    #num_heads: 1

rl_player_kwargs:
    obs_space: 66
    reward_kwargs:
        fainted_value: 0  # makes the agent really want to keep alive
        # it might be less likely to sacrifice a pokemon even if it makes it more likely to win
        hp_value: 0  # makes the agent really want to keep alive
        #number_of_pokemons: 6
        #starting_value: 0.0
        status_value: 0.0
        victory_value: 1

#opponent_name: random
#oppoennt